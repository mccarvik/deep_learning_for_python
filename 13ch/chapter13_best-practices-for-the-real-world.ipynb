{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Best practices for the real world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Getting the most out of your models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Using KerasTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# !pip install keras-tuner -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A KerasTuner model-building function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(hp):\n",
    "    units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(units, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A KerasTuner `HyperModel`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mccar\\AppData\\Local\\Temp\\ipykernel_1828\\1594418805.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "import kerastuner as kt\n",
    "\n",
    "class SimpleMLP(kt.HyperModel):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
    "        model = keras.Sequential([\n",
    "            layers.Dense(units, activation=\"relu\"),\n",
    "            layers.Dense(self.num_classes, activation=\"softmax\")\n",
    "        ])\n",
    "        optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"])\n",
    "        return model\n",
    "\n",
    "hypermodel = SimpleMLP(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "tuner = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    directory=\"mnist_kt_test\",\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': 'linear'}\n",
      "optimizer (Choice)\n",
      "{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 32s]\n",
      "val_accuracy: 0.9658499956130981\n",
      "\n",
      "Best val_accuracy So Far: 0.9739499986171722\n",
      "Total elapsed time: 01h 00m 31s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape((-1, 28 * 28)).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape((-1, 28 * 28)).astype(\"float32\") / 255\n",
    "x_train_full = x_train[:]\n",
    "y_train_full = y_train[:]\n",
    "num_val_samples = 10000\n",
    "x_train, x_val = x_train[:-num_val_samples], x_train[-num_val_samples:]\n",
    "y_train, y_val = y_train[:-num_val_samples], y_train[-num_val_samples:]\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "]\n",
    "tuner.search(\n",
    "    x_train, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=5,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Querying the best hyperparameter configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "top_n = 4\n",
    "best_hps = tuner.get_best_hyperparameters(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def get_best_epoch(hp):\n",
    "    model = build_model(hp)\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", mode=\"min\", patience=10)\n",
    "    ]\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=100,\n",
    "        batch_size=128,\n",
    "        callbacks=callbacks)\n",
    "    val_loss_per_epoch = history.history[\"val_loss\"]\n",
    "    best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    return best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "391/391 [==============================] - 5s 9ms/step - loss: 0.4280 - accuracy: 0.8864 - val_loss: 0.2270 - val_accuracy: 0.9365\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.2162 - accuracy: 0.9388 - val_loss: 0.1789 - val_accuracy: 0.9499\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1650 - accuracy: 0.9530 - val_loss: 0.1491 - val_accuracy: 0.9593\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1356 - accuracy: 0.9613 - val_loss: 0.1334 - val_accuracy: 0.9632\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1162 - accuracy: 0.9667 - val_loss: 0.1235 - val_accuracy: 0.9648\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1018 - accuracy: 0.9707 - val_loss: 0.1175 - val_accuracy: 0.9668\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0912 - accuracy: 0.9740 - val_loss: 0.1147 - val_accuracy: 0.9677\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0811 - accuracy: 0.9765 - val_loss: 0.1121 - val_accuracy: 0.9672\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0740 - accuracy: 0.9789 - val_loss: 0.1044 - val_accuracy: 0.9696\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0666 - accuracy: 0.9805 - val_loss: 0.1009 - val_accuracy: 0.9688\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.0616 - accuracy: 0.9826 - val_loss: 0.1020 - val_accuracy: 0.9709\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0560 - accuracy: 0.9844 - val_loss: 0.0975 - val_accuracy: 0.9707\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0508 - accuracy: 0.9857 - val_loss: 0.0967 - val_accuracy: 0.9707\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0473 - accuracy: 0.9865 - val_loss: 0.0981 - val_accuracy: 0.9718\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0439 - accuracy: 0.9875 - val_loss: 0.0970 - val_accuracy: 0.9713\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0405 - accuracy: 0.9891 - val_loss: 0.0971 - val_accuracy: 0.9716\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.0373 - accuracy: 0.9901 - val_loss: 0.0997 - val_accuracy: 0.9711\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0348 - accuracy: 0.9908 - val_loss: 0.0994 - val_accuracy: 0.9720\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0318 - accuracy: 0.9918 - val_loss: 0.1040 - val_accuracy: 0.9703\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0296 - accuracy: 0.9926 - val_loss: 0.1008 - val_accuracy: 0.9719\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0275 - accuracy: 0.9929 - val_loss: 0.1011 - val_accuracy: 0.9725\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.9939 - val_loss: 0.1056 - val_accuracy: 0.9720\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0236 - accuracy: 0.9943 - val_loss: 0.1009 - val_accuracy: 0.9735\n",
      "Best epoch: 13\n",
      "Epoch 1/15\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.3828 - accuracy: 0.8968\n",
      "Epoch 2/15\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1929 - accuracy: 0.9453\n",
      "Epoch 3/15\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1466 - accuracy: 0.9582\n",
      "Epoch 4/15\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1197 - accuracy: 0.9650\n",
      "Epoch 5/15\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1015 - accuracy: 0.9709\n",
      "Epoch 6/15\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0880 - accuracy: 0.9750\n",
      "Epoch 7/15\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0778 - accuracy: 0.9776\n",
      "Epoch 8/15\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0700 - accuracy: 0.9801\n",
      "Epoch 9/15\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0638 - accuracy: 0.9815\n",
      "Epoch 10/15\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0582 - accuracy: 0.9835\n",
      "Epoch 11/15\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0529 - accuracy: 0.9848\n",
      "Epoch 12/15\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0490 - accuracy: 0.9857\n",
      "Epoch 13/15\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0447 - accuracy: 0.9875\n",
      "Epoch 14/15\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0409 - accuracy: 0.9887\n",
      "Epoch 15/15\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0383 - accuracy: 0.9895\n",
      "313/313 [==============================] - 4s 6ms/step - loss: 0.0777 - accuracy: 0.9755\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 6s 9ms/step - loss: 0.4240 - accuracy: 0.8859 - val_loss: 0.2353 - val_accuracy: 0.9350\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2194 - accuracy: 0.9378 - val_loss: 0.1862 - val_accuracy: 0.9462\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1724 - accuracy: 0.9502 - val_loss: 0.1590 - val_accuracy: 0.9551\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1440 - accuracy: 0.9592 - val_loss: 0.1374 - val_accuracy: 0.9614\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1226 - accuracy: 0.9649 - val_loss: 0.1274 - val_accuracy: 0.9629\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1075 - accuracy: 0.9695 - val_loss: 0.1220 - val_accuracy: 0.9666\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0953 - accuracy: 0.9728 - val_loss: 0.1149 - val_accuracy: 0.9685\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0856 - accuracy: 0.9760 - val_loss: 0.1225 - val_accuracy: 0.9659\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0769 - accuracy: 0.9784 - val_loss: 0.1066 - val_accuracy: 0.9695\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0693 - accuracy: 0.9807 - val_loss: 0.1079 - val_accuracy: 0.9691\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0638 - accuracy: 0.9819 - val_loss: 0.1054 - val_accuracy: 0.9700\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.0576 - accuracy: 0.9837 - val_loss: 0.1074 - val_accuracy: 0.9701\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0530 - accuracy: 0.9849 - val_loss: 0.1043 - val_accuracy: 0.9699\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0489 - accuracy: 0.9863 - val_loss: 0.1043 - val_accuracy: 0.9708\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0450 - accuracy: 0.9878 - val_loss: 0.0996 - val_accuracy: 0.9731\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0410 - accuracy: 0.9884 - val_loss: 0.0996 - val_accuracy: 0.9707\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0384 - accuracy: 0.9891 - val_loss: 0.1024 - val_accuracy: 0.9702\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0352 - accuracy: 0.9902 - val_loss: 0.1022 - val_accuracy: 0.9723\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0324 - accuracy: 0.9914 - val_loss: 0.1032 - val_accuracy: 0.9720\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0300 - accuracy: 0.9919 - val_loss: 0.1007 - val_accuracy: 0.9728\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0281 - accuracy: 0.9927 - val_loss: 0.1037 - val_accuracy: 0.9727\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0256 - accuracy: 0.9937 - val_loss: 0.1010 - val_accuracy: 0.9716\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0241 - accuracy: 0.9938 - val_loss: 0.1055 - val_accuracy: 0.9717\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.0221 - accuracy: 0.9946 - val_loss: 0.1016 - val_accuracy: 0.9732\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0208 - accuracy: 0.9947 - val_loss: 0.1161 - val_accuracy: 0.9705\n",
      "Best epoch: 15\n",
      "Epoch 1/18\n",
      "469/469 [==============================] - 4s 5ms/step - loss: 0.3853 - accuracy: 0.8961\n",
      "Epoch 2/18\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1999 - accuracy: 0.9437\n",
      "Epoch 3/18\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1504 - accuracy: 0.9567\n",
      "Epoch 4/18\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1220 - accuracy: 0.9650\n",
      "Epoch 5/18\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.1036 - accuracy: 0.9700\n",
      "Epoch 6/18\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0892 - accuracy: 0.9741\n",
      "Epoch 7/18\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0790 - accuracy: 0.9774\n",
      "Epoch 8/18\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0710 - accuracy: 0.9791\n",
      "Epoch 9/18\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0643 - accuracy: 0.9813\n",
      "Epoch 10/18\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0584 - accuracy: 0.9826\n",
      "Epoch 11/18\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0531 - accuracy: 0.9843\n",
      "Epoch 12/18\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0491 - accuracy: 0.9857\n",
      "Epoch 13/18\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0454 - accuracy: 0.9872\n",
      "Epoch 14/18\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0418 - accuracy: 0.9882\n",
      "Epoch 15/18\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0385 - accuracy: 0.9890\n",
      "Epoch 16/18\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0351 - accuracy: 0.9898\n",
      "Epoch 17/18\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0328 - accuracy: 0.9908\n",
      "Epoch 18/18\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0303 - accuracy: 0.9913\n",
      "313/313 [==============================] - 3s 6ms/step - loss: 0.0830 - accuracy: 0.9765\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 6s 10ms/step - loss: 0.4170 - accuracy: 0.8881 - val_loss: 0.2372 - val_accuracy: 0.9337\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.2219 - accuracy: 0.9364 - val_loss: 0.1853 - val_accuracy: 0.9496\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.1744 - accuracy: 0.9504 - val_loss: 0.1550 - val_accuracy: 0.9558\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1435 - accuracy: 0.9585 - val_loss: 0.1390 - val_accuracy: 0.9618\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1225 - accuracy: 0.9648 - val_loss: 0.1337 - val_accuracy: 0.9621\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1063 - accuracy: 0.9692 - val_loss: 0.1255 - val_accuracy: 0.9640\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.0935 - accuracy: 0.9734 - val_loss: 0.1096 - val_accuracy: 0.9685\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0831 - accuracy: 0.9757 - val_loss: 0.1077 - val_accuracy: 0.9691\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0747 - accuracy: 0.9784 - val_loss: 0.1029 - val_accuracy: 0.9710\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0677 - accuracy: 0.9805 - val_loss: 0.0998 - val_accuracy: 0.9717\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0613 - accuracy: 0.9826 - val_loss: 0.0979 - val_accuracy: 0.9723\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.0553 - accuracy: 0.9846 - val_loss: 0.0970 - val_accuracy: 0.9725\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0508 - accuracy: 0.9850 - val_loss: 0.1004 - val_accuracy: 0.9712\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0467 - accuracy: 0.9871 - val_loss: 0.1020 - val_accuracy: 0.9703\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0427 - accuracy: 0.9877 - val_loss: 0.0945 - val_accuracy: 0.9741\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0389 - accuracy: 0.9889 - val_loss: 0.0945 - val_accuracy: 0.9736\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0359 - accuracy: 0.9904 - val_loss: 0.0923 - val_accuracy: 0.9747\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0326 - accuracy: 0.9914 - val_loss: 0.0932 - val_accuracy: 0.9746\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0299 - accuracy: 0.9918 - val_loss: 0.0916 - val_accuracy: 0.9765\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0284 - accuracy: 0.9922 - val_loss: 0.0943 - val_accuracy: 0.9748\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.0256 - accuracy: 0.9930 - val_loss: 0.0961 - val_accuracy: 0.9747\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0236 - accuracy: 0.9940 - val_loss: 0.0982 - val_accuracy: 0.9750\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0216 - accuracy: 0.9947 - val_loss: 0.0971 - val_accuracy: 0.9759\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0200 - accuracy: 0.9951 - val_loss: 0.0966 - val_accuracy: 0.9760\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0181 - accuracy: 0.9956 - val_loss: 0.0970 - val_accuracy: 0.9760\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.0987 - val_accuracy: 0.9760\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0152 - accuracy: 0.9966 - val_loss: 0.0959 - val_accuracy: 0.9768\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0140 - accuracy: 0.9969 - val_loss: 0.0978 - val_accuracy: 0.9775\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.0128 - accuracy: 0.9971 - val_loss: 0.1011 - val_accuracy: 0.9770\n",
      "Best epoch: 19\n",
      "Epoch 1/22\n",
      "469/469 [==============================] - 3s 4ms/step - loss: 0.3976 - accuracy: 0.8937\n",
      "Epoch 2/22\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2042 - accuracy: 0.9423\n",
      "Epoch 3/22\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1565 - accuracy: 0.9546\n",
      "Epoch 4/22\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.1279 - accuracy: 0.9631\n",
      "Epoch 5/22\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1082 - accuracy: 0.9687\n",
      "Epoch 6/22\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0944 - accuracy: 0.9726\n",
      "Epoch 7/22\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0832 - accuracy: 0.9755\n",
      "Epoch 8/22\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0747 - accuracy: 0.9782\n",
      "Epoch 9/22\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0669 - accuracy: 0.9804\n",
      "Epoch 10/22\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0609 - accuracy: 0.9819\n",
      "Epoch 11/22\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0556 - accuracy: 0.9834\n",
      "Epoch 12/22\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0511 - accuracy: 0.9851\n",
      "Epoch 13/22\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0465 - accuracy: 0.9863\n",
      "Epoch 14/22\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0431 - accuracy: 0.9873\n",
      "Epoch 15/22\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0398 - accuracy: 0.9887\n",
      "Epoch 16/22\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0368 - accuracy: 0.9902\n",
      "Epoch 17/22\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0341 - accuracy: 0.9902\n",
      "Epoch 18/22\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0314 - accuracy: 0.9912\n",
      "Epoch 19/22\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0296 - accuracy: 0.9914\n",
      "Epoch 20/22\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0277 - accuracy: 0.9921\n",
      "Epoch 21/22\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0256 - accuracy: 0.9933\n",
      "Epoch 22/22\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0236 - accuracy: 0.9937\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0851 - accuracy: 0.9759\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 5s 9ms/step - loss: 0.4250 - accuracy: 0.8859 - val_loss: 0.2332 - val_accuracy: 0.9329\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.2246 - accuracy: 0.9359 - val_loss: 0.1921 - val_accuracy: 0.9441\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1755 - accuracy: 0.9495 - val_loss: 0.1548 - val_accuracy: 0.9573\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1430 - accuracy: 0.9588 - val_loss: 0.1344 - val_accuracy: 0.9635\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1211 - accuracy: 0.9659 - val_loss: 0.1197 - val_accuracy: 0.9667\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1048 - accuracy: 0.9704 - val_loss: 0.1163 - val_accuracy: 0.9671\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0921 - accuracy: 0.9738 - val_loss: 0.1068 - val_accuracy: 0.9708\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0825 - accuracy: 0.9766 - val_loss: 0.1067 - val_accuracy: 0.9706\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0737 - accuracy: 0.9792 - val_loss: 0.1028 - val_accuracy: 0.9720\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0666 - accuracy: 0.9817 - val_loss: 0.1033 - val_accuracy: 0.9718\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0608 - accuracy: 0.9831 - val_loss: 0.0974 - val_accuracy: 0.9730\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0557 - accuracy: 0.9847 - val_loss: 0.0946 - val_accuracy: 0.9736\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0507 - accuracy: 0.9860 - val_loss: 0.0936 - val_accuracy: 0.9737\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0470 - accuracy: 0.9874 - val_loss: 0.0968 - val_accuracy: 0.9730\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0432 - accuracy: 0.9881 - val_loss: 0.0994 - val_accuracy: 0.9730\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0395 - accuracy: 0.9896 - val_loss: 0.0927 - val_accuracy: 0.9746\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0370 - accuracy: 0.9903 - val_loss: 0.0962 - val_accuracy: 0.9734\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0344 - accuracy: 0.9912 - val_loss: 0.0921 - val_accuracy: 0.9739\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0313 - accuracy: 0.9919 - val_loss: 0.1038 - val_accuracy: 0.9711\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.0288 - accuracy: 0.9927 - val_loss: 0.0970 - val_accuracy: 0.9727\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0268 - accuracy: 0.9933 - val_loss: 0.1000 - val_accuracy: 0.9741\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0251 - accuracy: 0.9939 - val_loss: 0.0968 - val_accuracy: 0.9737\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0230 - accuracy: 0.9942 - val_loss: 0.1007 - val_accuracy: 0.9733\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0211 - accuracy: 0.9950 - val_loss: 0.1015 - val_accuracy: 0.9734\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0193 - accuracy: 0.9951 - val_loss: 0.0974 - val_accuracy: 0.9745\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.0180 - accuracy: 0.9960 - val_loss: 0.1058 - val_accuracy: 0.9722\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 0.1086 - val_accuracy: 0.9747\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.0157 - accuracy: 0.9964 - val_loss: 0.1033 - val_accuracy: 0.9750\n",
      "Best epoch: 18\n",
      "Epoch 1/21\n",
      "469/469 [==============================] - 18s 6ms/step - loss: 0.3932 - accuracy: 0.8931\n",
      "Epoch 2/21\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1999 - accuracy: 0.9433\n",
      "Epoch 3/21\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1523 - accuracy: 0.9561\n",
      "Epoch 4/21\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.1246 - accuracy: 0.9641\n",
      "Epoch 5/21\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1050 - accuracy: 0.9694\n",
      "Epoch 6/21\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0911 - accuracy: 0.9737\n",
      "Epoch 7/21\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0797 - accuracy: 0.9766\n",
      "Epoch 8/21\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0713 - accuracy: 0.9793\n",
      "Epoch 9/21\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0639 - accuracy: 0.9817\n",
      "Epoch 10/21\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0579 - accuracy: 0.9832\n",
      "Epoch 11/21\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0528 - accuracy: 0.9848\n",
      "Epoch 12/21\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0481 - accuracy: 0.9862\n",
      "Epoch 13/21\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0443 - accuracy: 0.9873\n",
      "Epoch 14/21\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0406 - accuracy: 0.9886\n",
      "Epoch 15/21\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0374 - accuracy: 0.9893\n",
      "Epoch 16/21\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0342 - accuracy: 0.9904\n",
      "Epoch 17/21\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0314 - accuracy: 0.9915\n",
      "Epoch 18/21\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0293 - accuracy: 0.9914\n",
      "Epoch 19/21\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0266 - accuracy: 0.9927\n",
      "Epoch 20/21\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0247 - accuracy: 0.9932\n",
      "Epoch 21/21\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0222 - accuracy: 0.9941\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0923 - accuracy: 0.9756\n"
     ]
    }
   ],
   "source": [
    "def get_best_trained_model(hp):\n",
    "    best_epoch = get_best_epoch(hp)\n",
    "    model = build_model(hp)\n",
    "    model.fit(\n",
    "        x_train_full, y_train_full,\n",
    "        batch_size=128, epochs=int(best_epoch * 1.2))\n",
    "    return model\n",
    "\n",
    "best_models = []\n",
    "for hp in best_hps:\n",
    "    model = get_best_trained_model(hp)\n",
    "    model.evaluate(x_test, y_test)\n",
    "    best_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "best_models = tuner.get_best_models(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The art of crafting the right search space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The future of hyperparameter tuning: automated machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Model ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Scaling-up model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Speeding up training on GPU with mixed precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Understanding floating-point precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "np_array = np.zeros((2, 2))\n",
    "tf_tensor = tf.convert_to_tensor(np_array)\n",
    "tf_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.zeros((2, 2))\n",
    "tf_tensor = tf.convert_to_tensor(np_array, dtype=\"float32\")\n",
    "tf_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Mixed-precision training in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Multi-GPU training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Getting your hands on two or more GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Single-host, multi-device synchronous training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### TPU training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Using a TPU via Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Leveraging step fusing to improve TPU utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter13_best-practices-for-the-real-world.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
